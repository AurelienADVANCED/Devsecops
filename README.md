# Projet E5 DevSecOps â€“ ESTIAM Metz  
## Groupe WMD â€“ Rapport de rÃ©alisation  
**Nom : Aurelien ROSELLO**  
**BinÃ´me : Aurian BOHN**  
**Date : 16 avril 2025**

## ğŸ“š Sommaire

1. [ğŸ¯ Objectif du projet](#-objectif-du-projet)  
2. [ğŸ—ï¸ Architecture cible](#architecture-cible)
3. [ğŸ“ Organisation du projet](#-organisation-du-projet)  
4. [ğŸ”§ Ã‰tapes de rÃ©alisation](#-Ã©tapes-de-rÃ©alisation)  
5. [ğŸ³ CrÃ©ation des images Docker](#-crÃ©ation-des-images-docker)  
6. [ğŸš€ Optimisation des images Docker](#-optimisation-de-limage-docker-django)  
7. [ğŸŒ Ingress Kubernetes](#-ingress-kubernetes)  
8. [ğŸ“¦ DÃ©ploiement des applications Kubernetes](#-dÃ©ploiement-des-applications-kubernetes)  
9. [ğŸš€ Commandes de dÃ©ploiement Kubernetes](#-commandes-de-dÃ©ploiement-kubernetes)  
10. [âœ… Conclusion](#-conclusion)

---

## ğŸ¯ Objectif du projet

L'objectif de ce projet est de concevoir une maquette fonctionnelle dâ€™un cluster Kubernetes local capable dâ€™hÃ©berger trois applications web distinctes, dont une application critique dÃ©veloppÃ©e en Django.  
Chaque application doit Ãªtre exposÃ©e sur un port spÃ©cifique (80, 8080 et 9090) et dÃ©ployÃ©e Ã  lâ€™aide de fichiers manifeste Kubernetes indÃ©pendants.  
Toutes les images Docker doivent Ãªtre construites manuellement, optimisÃ©es, et intÃ©grÃ©es dans un dÃ©pÃ´t Git afin dâ€™assurer la traÃ§abilitÃ© et la portabilitÃ© de lâ€™environnement.

---

<a name="architecture-cible"></a>
## ğŸ—ï¸ Architecture cible

Lâ€™architecture repose sur un cluster Kubernetes local (via Minikube), hÃ©bergeant trois applications clonÃ©es et adaptÃ©es Ã  partir de dÃ©pÃ´ts publics :

- âœ… **Django Volt** â€“ [django-volt-1744777679](https://github.com/app-generator/django-volt-1744777679)  
- âœ… **Next.js** â€“ [hello-world-next-js](https://github.com/app-generator/hello-world-next-js)  
- âœ… **Flask** â€“ [flask-soft-1744678708](https://github.com/app-generator/flask-soft-1744678708)  

### ğŸ”€ SchÃ©ma logique

```
             Navigateur / Client
                     â”‚
                     â–¼
              [ Ingress NGINX ]
                     â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                â”‚                â”‚
   â–¼                â–¼                â–¼
  /django        /node (NodePort)  /flask (LB)
  Django          Next.js            Flask
   Port 80       Port 9090          Port 8080

```


### ğŸŒ RÃ©sumÃ© des accÃ¨s

| Application | Port exposÃ© | Type de service | AccÃ¨s via Ingress             | AccÃ¨s direct             |
|-------------|-------------|------------------|-------------------------------|---------------------------|
| Django      | 80          | ClusterIP        | `http://projet.local/django`  | `http://<minikube-ip>:80`        |
| Next.js     | 9090        | NodePort         | `http://projet.local/node`    | `http://<minikube-ip>:30080` |
| Flask       | 8080        | LoadBalancer     | `http://projet.local/flask`   | `http://<minikube-ip>:8080` (via tunnel) |

---
## ğŸ“ Organisation du projet

![image](https://github.com/user-attachments/assets/47765e81-565c-485c-b5c5-fa95039b50af)

ğŸ“¦ Chaque application dispose de son propre dossier avec son `Dockerfile`.  
ğŸ“‚ Tous les fichiers Kubernetes (`Deployment`, `Service`, `Ingress`) sont regroupÃ©s dans le dossier `k8s/` pour plus de clartÃ©.

---

## ğŸ”§ Ã‰tapes de rÃ©alisation

### ğŸ”¹ 1. Initialiser Minikube

```bash
minikube start
minikube addons enable ingress
minikube tunnel
```

## ğŸ³ CrÃ©ation des images Docker

### ğŸ“¦ 1. Application critique â€“ Django

**Fichier : django-volt/Dockerfile**

```dockerfile
FROM python:3.9

# set environment variables
ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1

COPY requirements.txt .
# install python dependencies
RUN pip install --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# Set UP
RUN python manage.py collectstatic --no-input
RUN python manage.py makemigrations
RUN python manage.py migrate

#__API_GENERATOR__
#__API_GENERATOR__END

# Start Server
EXPOSE 5005
CMD ["gunicorn", "--config", "gunicorn-cfg.py", "core.wsgi"]
```

# Commande de build :
```
docker build -t localhost/django-app:latest .
```

# Charger l'image dans Minikube :
```
minikube image load localhost/django-app:latest
```

![image](https://github.com/user-attachments/assets/c264f25f-557f-4e4c-ba0e-772e79b314c1)

## ğŸš€ Optimisation de l'image Docker Django

Afin de produire une image **plus lÃ©gÃ¨re, plus rapide Ã  dÃ©ployer et plus sÃ©curisÃ©e**, lâ€™image Docker de lâ€™application Django a Ã©tÃ© optimisÃ©e Ã  lâ€™aide dâ€™un **build multi-Ã©tapes**.

### ğŸ§± Ã‰tape 1 : Build intermÃ©diaire avec compilation

```dockerfile
FROM python:3.9-slim AS builder

ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1

WORKDIR /app
COPY requirements.txt .

# Installation des outils de compilation + dÃ©pendances
RUN apt-get update \
  && apt-get install -y build-essential gcc \
  && pip install --upgrade pip \
  && pip install --user --no-warn-script-location --no-cache-dir -r requirements.txt \
  && apt-get remove -y build-essential gcc \
  && apt-get autoremove -y \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*
```
### ğŸ“¦ Ã‰tape 2 : Image finale minimaliste

```dockerfile
FROM python:3.9-slim

ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1

WORKDIR /app

# RÃ©cupÃ©ration des paquets Python installÃ©s depuis l'Ã©tape prÃ©cÃ©dente
COPY --from=builder /root/.local /root/.local
ENV PATH=/root/.local/bin:$PATH

# Copie du code source Django
COPY . .

# PrÃ©paration des fichiers statiques + migrations
RUN python manage.py collectstatic --no-input && \
    python manage.py makemigrations && \
    python manage.py migrate

EXPOSE 5005

CMD ["gunicorn", "--config", "gunicorn-cfg.py", "core.wsgi"]
```

ğŸ” .dockerignore
```dockerfile
# RÃ©pertoires de dev
__pycache__/
*.py[cod]
*.sqlite3
*.log
*.env
*.db
*.bak
*.swp

# RÃ©pertoires spÃ©cifiques
.env/
venv/
env/
.idea/
.vscode/
.mypy_cache/
.coverage
node_modules/

# Git
.git/
.gitignore

# Fichiers gÃ©nÃ©rÃ©s par collectstatic
staticfiles/
static/

# Docker
Dockerfile
.dockerignore
```
![image](https://github.com/user-attachments/assets/57576e4b-8513-43d7-9a08-117c79ead657)

# ğŸ“¦ 2. Application secondaire â€“ Next.js
## Fichier : hello-world-next-js/Dockerfile
```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY . .
RUN npm install
RUN npm run build
EXPOSE 8080
CMD ["npm", "start"]
```
## Commande de build :
```
docker build -t localhost/nextjs-app:1.0 .
```

## Charger lâ€™image dans Minikube :
```
docker build -t localhost/nextjs-app:1.0 .
```

ğŸ” .dockerignore
```dockerfile
node_modules/
.next/
.env
*.log
.git/
.gitignore
Dockerfile
docker-compose.yml
```

# 3. Application Flask
## Fichier : flask-soft/Dockerfile
```dockerfile
FROM python:3.11-alpine

# Eviter l'Ã©criture de fichiers pyc + affichage live dans le terminal
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Installation des dÃ©pendances systÃ¨me
RUN apk update && apk add --no-cache \
    build-base \
    python3-dev \
    libffi-dev \
    musl-dev \
    gcc \
    jpeg-dev \
    zlib-dev \
    postgresql-dev \
    mariadb-dev \
    linux-headers

# Dossier de travail
WORKDIR /app

# Copier requirements en premier pour profiter du cache
COPY requirements.txt .

# Installer les dÃ©pendances
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Copier tout le reste du code
COPY . .

# Port exposÃ© : 8080 (selon les besoins du client)
EXPOSE 8080

# Lancement de lâ€™app avec Gunicorn en mode production
CMD ["gunicorn", "--bind", "0.0.0.0:8080", "run:app"]
```

# Commande de build :
```
docker build -t localhost/flask-app:latest .
```

# Charger l'image dans Minikube :
```
minikube image load localhost/flask-app:latest
```

ğŸ” .dockerignore
```dockerfile
 docker
# Python
__pycache__/
*.py[cod]
*.log
*.sqlite3
*.env
*.db
*.swp
*.bak

# Environnement virtuel
venv/
env/

# IDE & outils
.vscode/
.idea/
.mypy_cache/

# Node.js (si jamais intÃ©grÃ© pour frontend)
node_modules/

# Git
.git/
.gitignore

# Media & statiques gÃ©nÃ©rÃ©s
media/
static/

# Docker
Dockerfile
.dockerignore
```

![image](https://github.com/user-attachments/assets/f13d0ec4-9251-4f75-8c7d-147ca1d14817)

## ğŸŒ Ingress Kubernetes

Le fichier suivant permet de dÃ©finir un Ingress unique exposant les trois applications sur un seul domaine avec des chemins distincts pour chaque service.

**Fichier : `k8s/ingress.yaml`**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
    - http:
        paths:
          - path: /django
            pathType: Prefix
            backend:
              service:
                name: django-service
                port:
                  number: 80
          - path: /flask
            pathType: Prefix
            backend:
              service:
                name: flask-service
                port:
                  number: 8080
          - path: /front
            pathType: Prefix
            backend:
              service:
                name: next-js-service
                port:
                  number: 9090
```

![image](https://github.com/user-attachments/assets/61c8cab3-5f11-4651-b1ee-567f81136825)

# ğŸ“¦ DÃ©ploiement des applications Kubernetes

## âš™ï¸ DÃ©ploiement de l'application Node.js (port 8080)

**Fichier : `k8s/node-deployment.yaml`**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: node
  template:
    metadata:
      labels:
        app: node
    spec:
      containers:
        - name: node
          image: node-app:1.0
          ports:
            - containerPort: 8080
```

Fichier : k8s/node-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: node-service
spec:
  type: NodePort
  selector:
    app: node
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 30080
```

## âš™ï¸ DÃ©ploiement de l'application statique NGINX (port 9090)
Fichier : k8s/nginx-deployment.yaml
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx-app:1.0
          ports:
            - containerPort: 9090
```
Fichier : k8s/nginx-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
    - port: 9090
      targetPort: 9090
```

## ğŸš€ Commandes de dÃ©ploiement Kubernetes

Voici les commandes Ã  exÃ©cuter pour dÃ©ployer tous les composants dans le cluster :

```bash
# DÃ©ployer l'Ingress
k apply -f k8s/ingress.yml

# DÃ©ployer l'application Django
k apply -f k8s/django-deployment.yml
k apply -f k8s/django-service.yml

# DÃ©ployer l'application Next.js
k apply -f k8s/next-js-deployment.yml
k apply -f k8s/next-js-service.yml

# DÃ©ployer l'application Flask
k apply -f k8s/flask-deployment.yml
k apply -f k8s/flask-service.yml
```

## âœ… Conclusion

Ce projet nous a permis de mettre en place une maquette fonctionnelle dâ€™un cluster Kubernetes local, capable dâ€™hÃ©berger et de faire cohabiter trois applications web distinctes : Django (critique), Next.js, et Flask.

GrÃ¢ce Ã  lâ€™utilisation de fichiers `Dockerfile` adaptÃ©s, dâ€™images optimisÃ©es et de manifests Kubernetes sÃ©parÃ©s pour chaque composant, nous avons pu respecter les exigences de modularitÃ©, de portabilitÃ© et de scalabilitÃ© imposÃ©es par le client.

Lâ€™usage dâ€™un Ingress unique a facilitÃ© lâ€™accÃ¨s aux services via une seule URL (`projet.local`), tout en respectant les rÃ¨gles de routage propres Ã  chaque application. Le tout est documentÃ©, versionnÃ©, et prÃªt Ã  Ãªtre migrÃ© dans un environnement de production cloud ou intÃ©grÃ© Ã  une pipeline CI/CD.

ğŸ¯ **CompÃ©tences mobilisÃ©es** :
- Docker & optimisation des images
- Architecture Kubernetes (Minikube, Services, Ingress, etc.)
- Gestion multi-applications et exposition centralisÃ©e
- Automatisation du dÃ©ploiement

Le projet est prÃªt pour une dÃ©monstration, un audit technique, ou une future industrialisation.
